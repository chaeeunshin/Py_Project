{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeb750f4-cccf-44b7-96bc-d81437357201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   variance  skewness  curtosis  entropy  class\n",
      "0   3.62160    8.6661   -2.8073 -0.44699      1\n",
      "1   4.54590    8.1674   -2.4586 -1.46210      1\n",
      "2   3.86600   -2.6383    1.9242  0.10645      1\n",
      "3   3.45660    9.5228   -4.0112 -3.59440      1\n",
      "4   0.32924   -4.4552    4.5718 -0.98880      1\n",
      "(1372, 5)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('banknote.csv')\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9191bafd-8e09-4c68-9ca1-407f8b1463e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097, 4)\n",
      "(275, 4)\n"
     ]
    }
   ],
   "source": [
    "x = df.drop('class', axis=1) #predictors\n",
    "#drop is used to drop specified labels, axis=1 means a column, and axis=0 means a row\n",
    "y = df['class'] #response variable\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=123)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "498fa097-862f-483b-afbd-a3e094a6b074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1\n",
      " 1 1 0 0 1 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0\n",
      " 1 1 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1\n",
      " 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0\n",
      " 1 1 0 0 1 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Fitting a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#Making predictions\n",
    "y_pred = model.predict(x_test)\n",
    "#It is binary prediction\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29c30766-1d4b-4186-b362-c44204185576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "[[128   0]\n",
      " [  3 144]]\n"
     ]
    }
   ],
   "source": [
    "#Generating the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix: \")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ec07803-6fd7-486f-a12d-1ab1b57d1fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy:  0.9890909090909091\n"
     ]
    }
   ],
   "source": [
    "#Calculating overall accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Overall accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "245c90a9-f973-4a7c-b2e9-7b4e21fc53c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity score:  0.9795918367346939\n"
     ]
    }
   ],
   "source": [
    "#Calculating sensitivity\n",
    "sensitivity = recall_score(y_test,y_pred)\n",
    "print(\"Sensitivity score: \", sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37eacb86-ceef-41e1-9be6-3e2dde313c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity score:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Calculating specificity\n",
    "specificity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "print(\"Specificity score: \", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0516b6e5-d2ed-4f8e-927a-1604b3a185f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
