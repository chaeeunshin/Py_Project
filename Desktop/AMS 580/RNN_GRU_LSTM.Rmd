---
title: Recurrent Neural Networks(RNN) and Long Short-Term Memory(LSTM)
output: pdf_document
---
```{r}
library(keras)
library(tensorflow)
library(caret)
```
#1. Generate a sine wave with the function sin(x) for x ranging 0 to 20, resulting in a total of 400 points. Plot the generated sequence
```{r}
data <- sin(seq(0,20,length.out=400))
plot(as.vector(data),col='blue',type='l',ylab='X,Y',main='sine wave')
```
#2. Divide the cleaned dataset into two parts, the last 10 points for testing y and the rest for training.
```{r}
train_data <- data[1:390]

maxlen <- 10 #length of the sequences
X <- array(data=NA,dim=c(length(train_data)-maxlen,maxlen))
y <- data[(maxlen+1):length(train_data)]

for(i in 1:(length(train_data)-maxlen)) {
  X[i,] <- train_data[i:(i+maxlen-1)]
}

# Reshape input to be [samples, time steps, features]
X <- array(X,dim=c(dim(X)[1],dim(X)[2],1))
y <- array(y, dim=c(380,1))
```

Define and Compile the model
```{r}
set.seed(123)
model_rnn <- keras_model_sequential() %>%
  layer_simple_rnn(units=32,input_shape=c(maxlen,1)) %>%
  layer_dense(units=1)

model_rnn %>% compile(
  loss='mean_squared_error',
  optimizer=optimizer_adam())

model_lstm <- keras_model_sequential() %>%
  layer_lstm(units=32,input_shape=c(maxlen,1)) %>%
  layer_dense(units=1)

model_lstm %>% compile(
  loss='mean_squared_error',
  optimizer=optimizer_adam()
)
```

Model fitting
```{r}
history_rnn <- model_rnn %>% fit(X,y,
                                 eopchs=20, 
                                 batch_size=8
                                 )

history_lstm <- model_lstm %>% fit(X,y,
                                   epochs=20,
                                   batch_size=8
                                   )
```

Training loss
To evaluate the models and visualize their performance, we can fit assess the loss over epochs during training, and then evaluate the models on some validation or test data if available.
```{r}
plot(history_rnn$metrics$loss,type='l',col='blue',xlab='Epoch',ylab='loss',main='Training Loss for RNN')

plot(history_lstm$metics$loss,type='l',col='red',xlab='Epoch',ylab='Loss',main='Training Loss for LSTM')
```

Make predictions
```{r}
test_data <- data[381:400]
test_X <- array(data=NA,dim=c(length(test_data)-maxlen,maxlen))
for(i in 1:(length(test_data)-maxlen)) {
  test_X[i,] <- test_data[i:(i+maxlen-1)]
}

test_X <- array(test_X, dim=c(dim(test_X)[1],dim(test_X)[2],1))

predictions_rnn <- model_rnn %>% predict(test_X)
(MSE.rnn = RMSE(predictions_rnn,data[391:400]))

predictions_lstm <- model_lstm %>% predict(test_X)
(MSE.lstm = RMSE(predictions_lstm,data[391:400]))
```

Plot the predictions along with the actual data
```{r}
plot(data[391:400],type='l',col='black',xlab='time',ylab='value',main='Model predictions vs. Actual data')
lines(predictions_rnn,col='blue',lty=2)
lines(predictions_lstm,col='red',lty=2)
legend("topright",legend=c("Actual","RNN prediction", "LSTM prediction"),col=c('black','blue','red'))
```